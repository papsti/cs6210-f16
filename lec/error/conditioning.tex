\section{Forward and backward error}

We often approximate a function $f$ by another function $\hat{f}$.
For a particular $x$, the {\em forward} (absolute) error is
\[
  |\hat{f}(x)-f(x)|.
\]
In words, forward error is the function {\em output}.  Sometimes,
though, we can think of a slightly wrong {\em input}:
\[
  \hat{f}(x) = f(\hat{x}).
\]
In this case, $|x-\hat{x}|$ is called the {\em backward} error.
An algorithm that always has small backward error is {\em backward stable}.

A {\em condition number} a tight constant relating relative output
error to relative input error.  For example, for the problem of
evaluating a sufficiently nice function $f(x)$ where $x$ is the input
and $\hat{x} = x+h$ is a perturbed input (relative error $|h|/|x|$),
the condition number $\kappa[f(x)]$ is the smallest constant such that
\[
  \frac{|f(x+h)-f(x)|}{|f(x)|} \leq \kappa[f(x)] \frac{|h|}{|x|} + o(|h|)
\]
If $f$ is differentiable, the condition number is
\[
\kappa[f(x)] =
  \lim_{h \neq 0} \frac{|f(x+h)-f(x)|/|f(x)|}{|(x+h)-x|/|x|} =
  \frac{|f'(x)||x|}{|f(x)|}.
\]
If $f$ is Lipschitz in a neighborhood of $x$ (locally Lipschitz), then
\[
\kappa[f(x)] =
  \frac{M_{f(x)}|x|}{|f(x)|}.
\]
where $M_f$ is the smallest constant such that
$|f(x+h)-f(x)| \leq M_f |h| + o(|h|)$.  When the problem has no linear
bound on the output error relative to the input error, we sat the
problem has an {\em infinite} condition number.  An example is
$x^{1/3}$ at $x = 0$.

A problem with a small condition number is called {\em well-conditioned};
a problem with a large condition number is {\em ill-conditioned}.
A backward stable algorithm applied to a well-conditioned problem has
a small forward error.
