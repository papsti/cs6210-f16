\section{Double trouble}

The simple shift strategy we described in the previous section gives
{\em local} quadratic convergence, but it is not {\em globally} convergent.
%% For example, suppose $P$ is a cyclic permutation matrix, i.e.
%% \[
%%   P = \begin{bmatrix}
%%         0 & 0 & \cdots & 0 & 1 \\
%%         1 & 0 & \cdots & 0 & 0 \\
%%         0 & 1 & \cdots & 0 & 0 \\
%%         \vdots & \ddots & \ddots & \vdots & \vdots \\
%%         0 & 0 & \cdots & 1 & 0
%%      \end{bmatrix}
%% \]
%% The matrix $P$ is a {\em fixed point} for the shifted QR iteration
%% (\ref{sqr-1})--(\ref{sqr-2}) when we choose
%% $\sigma_k = e_n^* A^{(k)} e_n = 0$.
%
As a particularly pesky example, consider what happens if we
want to compute a complex conjugate pair of eigenvalues of a real
matrix.  With our simple shifting strategy, 
%the iteration (\ref{sqr-1})--(\ref{sqr-2}) will 
the QR iteration
never produce a complex iterate, a
complex shift, or a complex eigenvalue.  The best we can hope for is
that our initial shift is closer to both eigenvalues in the conjugate
pair than it is to anything else in the spectrum; in this case, we
will most likely find that the last two columns of $\uQ^{(k)}$ are
converging to a basis for an {\em invariant row subspace} of $A$,
and the corresponding eigenvalues are the eigenvalues of the trailing
2-by-2 sub-block.

Fortunately, we know how to compute the eigenvalues of a 2-by-2
matrix!  This suggests the following shift strategy: let $\sigma_k$ be
one of the eigenvalues of $A^{(k)}(n-1:n,n-1:n)$.  Because this 2-by-2
problem can have complex roots even when the matrix is real, this
shift strategy allows the possibility that we could converge to
complex eigenvalues. On the other hand, if our original matrix is
real, perhaps we would like to consider the {\em real} Schur form, in
which $U$ is a real matrix and $T$ is block diagonal with 1-by-1 and
2-by-2 diagonal blocks that correspond, respectively, to real and
complex eigenvalues.  If we shift with {\em both} roots of
$A^{(k)}(n-1:n,n-1:n)$, equivalent to computing
\begin{align*}
  Q^{(k)} R^{(k)} &= (A^{(k-1)} - \sigma_{k+} I)(A^{(k-1)} - \sigma_{k-}) \\
  A^{(k)} &= (Q^{(k)})^* A^{(k-1)} Q^{(k)}. \label{sqr-2}
\end{align*}
There is one catch here: even if we started with $A^{(0)}$ in Hessenberg
form, it is unclear how to do this double-shift step in $O(n^2)$ time!

The following fact will prove our salvation: if we $Q$ and $V$ are
both orthogonal matrices and $Q^T A Q$ and $V^T A V$ are both
(unreduced) Hessenberg\footnote{ An unreduced Hessenberg matrix has no
  zeros on the first subdiagonal.  })  and the first column of $Q$ is
the same as the first column of $V$, then all successive columns of
$Q$ are unit scalar multiples of the corresponding columns of $V$.
This is the {\em implicit Q theorem}.  Practically, it means that we
can do any sort of shifted QR step we would like in the following way:
\begin{enumerate}
\item
  Apply as a similarity any transformations in the QR decomposition
  that affect the leading submatrix (1-by-1 or 2-by-2).
\item
  Restore the resulting matrix to Hessenberg form without further
  transformations to the leading submatrix.
\end{enumerate}
In the first step, we effectively compute the first column of $Q$;
in the second step, we effectively compute the remaining columns.
Certainly we compute {\em some} transformation with the right leading
column; and the implicit Q theorem tells us that any such transformation
is basically the one we would have computed with an ordinary QR step.

Last time, we discussed the Wilkinson strategy of choosing as a shift
one of the roots of the trailing 2-by-2 submatrix of $A^{(k)}$ (the
one closest to the final entry).  We also noted that if we want to
convert to {\em real} Schur form, the Wilkinson shift has the distinct
disadvantage that it might launch us into the complex plane.  The
Francis shift strategy is to simultaneously apply a complex conjugate
pair of shifts, essentially computing two steps together:
\begin{align*}
  Q^{(k)} R^{(k)} &= (A^{(k-1)}-\sigma_k I)(A^{(k-1)}-\bar{\sigma}_k I) \\
                &= (A^{(k-1)})^2 - 2\Re(\sigma_k) A^{(k-1)} + |\sigma_k|^2 I \\
  A^{(k)}        &= (Q^{(k)})^* A^{(k-1)} (Q^{(k)}).
\end{align*}
When the Wilkinson shift is real, we let $\sigma_k$ be the same as the
Wilkinson shift; when the Wilkinson strategy leads to a conjugate pair
of possible shifts, we use both, maintaining efficiency by doing the
steps {\em implicitly}.  Let's now make this implicit magic a little
more explicit by building code for an implicit double-shift QR step.

Our first step will be to construct the polynomial associated with the
Francis double-shift.  In the case where the trailing 2-by-2 submatrix
(or 2-by-2 block Rayleigh quotient, if one prefers) has a complex pair
of eigenvalues, we just use its characteristic polynomial.  Otherwise,
we use the polynomial associated with two steps with a Wilkinson shift.

\lstinputlisting{code/eigen/francis_poly.m}

The code {\tt francis\_poly} gives us coefficients $b_k$ and $c_k$ for a
quadratic function $s_k(z) = z^2 + b_k z + c_k$.  We now want to compute
\begin{align*}
  Q^{(k)} R^{(k)} &= s_k(A^{(k-1)}) = (A^{(k-1)})^2 + b_k A^{(k-1)} + c_k I \\
  A^{(k)}        &= (Q^{(k)})^* A^{(k-1)} (Q^{(k)}).
\end{align*}
The trick is to realize that all the iterates $A^{(k)}$ are Hessenberg,
and the Hessenberg form for a matrix is usually unique (up to signs).
Therefore, we compute the first Householder transformation $W$ in a
QR factorization of $s_k(A^{(k)}$ explicitly.  The first column of $Q^{(k)}$
is the same as the first column of $W$.  The remaining columns of $Q^{(k)}$
can be determined by the requirement that $A^{(k)}$ is in Hessenberg form.
We compute them implicitly by applying the usual Hessenberg reduction algorithm
to $B = WA^{(k-1)}W$, taking advantage of the fact that $B$ has special
structure to do $O(n^2)$ work.  Each step of the reduction moves a ``bulge''
down the diagonal by one.

\lstinputlisting{code/eigen/hessqr_francis.m}

In the LAPACK codes, the Francis double-shift strategy is mixed with
some ``exceptional shifts'' that occur every few iterations.
These exceptional shifts serve to keep the algorithm from getting
stuck in certain pathological situations (e.g. a cyclic permutation
matrix).
